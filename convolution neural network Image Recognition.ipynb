{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda26d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe30e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b33271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8cc965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory('training_set/training_set',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "040846e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen =ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set/test_set',\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be034ab0",
   "metadata": {},
   "source": [
    "# CNN mimarisi olusturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c21ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe4efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = [64,64,3]))\n",
    "# burada convolution islemi ile resimler 64x64 formata gelcek , 3 parametresi ise rgb yani 3 renk boyutunu temsil ediyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcd2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "#stride ilerleme adimini temsil eder. pooling katmani burasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "162336d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. convolution katmani burasidir\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95df37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening islemi ile noronun anlayacagi sekilde 1 boyuta getiriyoruz\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a7b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c452e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cikis katmani. Sigmoid sectik cunku classidication yapcaz sonucunda kopek mi kedimi gibi bir siniflandirm olacak\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d18fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss = 'binary_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73094cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 101s 398ms/step - loss: 0.6795 - accuracy: 0.5759 - val_loss: 0.6112 - val_accuracy: 0.6861\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.6038 - accuracy: 0.6737 - val_loss: 0.6289 - val_accuracy: 0.6466\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.5650 - accuracy: 0.7063 - val_loss: 0.5319 - val_accuracy: 0.7449\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 42s 166ms/step - loss: 0.5499 - accuracy: 0.7171 - val_loss: 0.5572 - val_accuracy: 0.7133\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.5147 - accuracy: 0.7460 - val_loss: 0.5310 - val_accuracy: 0.7444\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.5041 - accuracy: 0.7579 - val_loss: 0.4973 - val_accuracy: 0.7677\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.4819 - accuracy: 0.7733 - val_loss: 0.5016 - val_accuracy: 0.7543\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.4724 - accuracy: 0.7711 - val_loss: 0.4792 - val_accuracy: 0.7677\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.4671 - accuracy: 0.7806 - val_loss: 0.5114 - val_accuracy: 0.7578\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.4532 - accuracy: 0.7834 - val_loss: 0.5289 - val_accuracy: 0.7469\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4736 - val_accuracy: 0.7766\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.4326 - accuracy: 0.8004 - val_loss: 0.4755 - val_accuracy: 0.7795\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.4209 - accuracy: 0.8051 - val_loss: 0.4483 - val_accuracy: 0.7963\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.4123 - accuracy: 0.8076 - val_loss: 0.4497 - val_accuracy: 0.7968\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.4053 - accuracy: 0.8117 - val_loss: 0.4587 - val_accuracy: 0.7934\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.4005 - accuracy: 0.8151 - val_loss: 0.4876 - val_accuracy: 0.7899\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.3914 - accuracy: 0.8242 - val_loss: 0.4529 - val_accuracy: 0.7914\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.3915 - accuracy: 0.8235 - val_loss: 0.4462 - val_accuracy: 0.8028\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 43s 169ms/step - loss: 0.3849 - accuracy: 0.8254 - val_loss: 0.4296 - val_accuracy: 0.8107\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 43s 171ms/step - loss: 0.3654 - accuracy: 0.8391 - val_loss: 0.4417 - val_accuracy: 0.8062\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.3598 - accuracy: 0.8374 - val_loss: 0.4508 - val_accuracy: 0.8028\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.3586 - accuracy: 0.8425 - val_loss: 0.4494 - val_accuracy: 0.8003\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.3467 - accuracy: 0.8482 - val_loss: 0.4437 - val_accuracy: 0.8047\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.3423 - accuracy: 0.8503 - val_loss: 0.4631 - val_accuracy: 0.8028\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.3303 - accuracy: 0.8572 - val_loss: 0.4640 - val_accuracy: 0.7998\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.3362 - accuracy: 0.8552 - val_loss: 0.4749 - val_accuracy: 0.7954\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 0.3177 - accuracy: 0.8597 - val_loss: 0.4770 - val_accuracy: 0.8038\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 44s 177ms/step - loss: 0.3221 - accuracy: 0.8597 - val_loss: 0.4563 - val_accuracy: 0.8023\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 0.3096 - accuracy: 0.8646 - val_loss: 0.4526 - val_accuracy: 0.8240\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 42s 169ms/step - loss: 0.3038 - accuracy: 0.8695 - val_loss: 0.4518 - val_accuracy: 0.8211\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 43s 172ms/step - loss: 0.2947 - accuracy: 0.8712 - val_loss: 0.4433 - val_accuracy: 0.8176\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 46s 183ms/step - loss: 0.2921 - accuracy: 0.8741 - val_loss: 0.4534 - val_accuracy: 0.8107\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 46s 182ms/step - loss: 0.2870 - accuracy: 0.8791 - val_loss: 0.4710 - val_accuracy: 0.8146\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 46s 182ms/step - loss: 0.2849 - accuracy: 0.8788 - val_loss: 0.4972 - val_accuracy: 0.8013\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 47s 187ms/step - loss: 0.2713 - accuracy: 0.8791 - val_loss: 0.4757 - val_accuracy: 0.8127\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 46s 183ms/step - loss: 0.2733 - accuracy: 0.8829 - val_loss: 0.4793 - val_accuracy: 0.8038\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 45s 181ms/step - loss: 0.2553 - accuracy: 0.8928 - val_loss: 0.4722 - val_accuracy: 0.8181\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 45s 181ms/step - loss: 0.2515 - accuracy: 0.8923 - val_loss: 0.4670 - val_accuracy: 0.8201\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 47s 186ms/step - loss: 0.2511 - accuracy: 0.8911 - val_loss: 0.4574 - val_accuracy: 0.8186\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 43s 173ms/step - loss: 0.2481 - accuracy: 0.8924 - val_loss: 0.5250 - val_accuracy: 0.7904\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 43s 172ms/step - loss: 0.2378 - accuracy: 0.9004 - val_loss: 0.5152 - val_accuracy: 0.8077\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 49s 196ms/step - loss: 0.2380 - accuracy: 0.8991 - val_loss: 0.5517 - val_accuracy: 0.7934\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2264 - accuracy: 0.9053 - val_loss: 0.5201 - val_accuracy: 0.8156\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 55s 220ms/step - loss: 0.2320 - accuracy: 0.9023 - val_loss: 0.5510 - val_accuracy: 0.8013\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 48s 192ms/step - loss: 0.2210 - accuracy: 0.9084 - val_loss: 0.6001 - val_accuracy: 0.7815\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 48s 190ms/step - loss: 0.2213 - accuracy: 0.9087 - val_loss: 0.5266 - val_accuracy: 0.8176\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 48s 189ms/step - loss: 0.2094 - accuracy: 0.9153 - val_loss: 0.5467 - val_accuracy: 0.8062\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 48s 189ms/step - loss: 0.2060 - accuracy: 0.9174 - val_loss: 0.6072 - val_accuracy: 0.7840\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 48s 190ms/step - loss: 0.2059 - accuracy: 0.9171 - val_loss: 0.5242 - val_accuracy: 0.8028\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 49s 193ms/step - loss: 0.1920 - accuracy: 0.9215 - val_loss: 0.5469 - val_accuracy: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17bc6afb820>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set,validation_data= test_set,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3b93725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(\"C:/Users/dteme/OneDrive/Masaüstü/udemy-ML/image/dog4.jfif\",target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "905a0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69dd0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99349097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
